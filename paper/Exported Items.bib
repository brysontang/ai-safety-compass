
@misc{carlsmith_is_2024,
	title = {Is Power-Seeking {AI} an Existential Risk?},
	url = {http://arxiv.org/abs/2206.13353},
	doi = {10.48550/arXiv.2206.13353},
	abstract = {This report examines what I see as the core argument for concern about existential risk from misaligned artificial intelligence. I proceed in two stages. First, I lay out a backdrop picture that informs such concern. On this picture, intelligent agency is an extremely powerful force, and creating agents much more intelligent than us is playing with fire -- especially given that if their objectives are problematic, such agents would plausibly have instrumental incentives to seek power over humans. Second, I formulate and evaluate a more specific six-premise argument that creating agents of this kind will lead to existential catastrophe by 2070. On this argument, by 2070: (1) it will become possible and financially feasible to build relevantly powerful and agentic {AI} systems; (2) there will be strong incentives to do so; (3) it will be much harder to build aligned (and relevantly powerful/agentic) {AI} systems than to build misaligned (and relevantly powerful/agentic) {AI} systems that are still superficially attractive to deploy; (4) some such misaligned systems will seek power over humans in high-impact ways; (5) this problem will scale to the full disempowerment of humanity; and (6) such disempowerment will constitute an existential catastrophe. I assign rough subjective credences to the premises in this argument, and I end up with an overall estimate of {\textasciitilde}5\% that an existential catastrophe of this kind will occur by 2070. (May 2022 update: since making this report public in April 2021, my estimate here has gone up, and is now at {\textgreater}10\%.)},
	number = {{arXiv}:2206.13353},
	publisher = {{arXiv}},
	author = {Carlsmith, Joseph},
	urldate = {2025-03-21},
	date = {2024-08-13},
	eprinttype = {arxiv},
	eprint = {2206.13353 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/brysontang/Zotero/storage/IIBC4Z9R/Carlsmith - 2024 - Is Power-Seeking AI an Existential Risk.pdf:application/pdf;Snapshot:/Users/brysontang/Zotero/storage/ZUPGGQ93/2206.html:text/html},
}
