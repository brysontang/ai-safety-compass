
@misc{grace_thousands_2024,
	title = {Thousands of {AI} Authors on the Future of {AI}},
	url = {http://arxiv.org/abs/2401.02843},
	doi = {10.48550/arXiv.2401.02843},
	abstract = {In the largest survey of its kind, 2,778 researchers who had published in top-tier artificial intelligence ({AI}) venues gave predictions on the pace of {AI} progress and the nature and impacts of advanced {AI} systems The aggregate forecasts give at least a 50\% chance of {AI} systems achieving several milestones by 2028, including autonomously constructing a payment processing site from scratch, creating a song indistinguishable from a new song by a popular musician, and autonomously downloading and fine-tuning a large language model. If science continues undisrupted, the chance of unaided machines outperforming humans in every possible task was estimated at 10\% by 2027, and 50\% by 2047. The latter estimate is 13 years earlier than that reached in a similar survey we conducted only one year earlier [Grace et al., 2022]. However, the chance of all human occupations becoming fully automatable was forecast to reach 10\% by 2037, and 50\% as late as 2116 (compared to 2164 in the 2022 survey). Most respondents expressed substantial uncertainty about the long-term value of {AI} progress: While 68.3\% thought good outcomes from superhuman {AI} are more likely than bad, of these net optimists 48\% gave at least a 5\% chance of extremely bad outcomes such as human extinction, and 59\% of net pessimists gave 5\% or more to extremely good outcomes. Between 38\% and 51\% of respondents gave at least a 10\% chance to advanced {AI} leading to outcomes as bad as human extinction. More than half suggested that "substantial" or "extreme" concern is warranted about six different {AI}-related scenarios, including misinformation, authoritarian control, and inequality. There was disagreement about whether faster or slower {AI} progress would be better for the future of humanity. However, there was broad agreement that research aimed at minimizing potential risks from {AI} systems ought to be prioritized more.},
	number = {{arXiv}:2401.02843},
	publisher = {{arXiv}},
	author = {Grace, Katja and Stewart, Harlan and Sandk√ºhler, Julia Fabienne and Thomas, Stephen and Weinstein-Raun, Ben and Brauner, Jan},
	urldate = {2025-03-10},
	date = {2024-04-30},
	eprinttype = {arxiv},
	eprint = {2401.02843 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
	file = {Full Text PDF:/Users/brysontang/Zotero/storage/PVC58BYT/Grace et al. - 2024 - Thousands of AI Authors on the Future of AI.pdf:application/pdf;Snapshot:/Users/brysontang/Zotero/storage/P2AIBSGV/2401.html:text/html},
}
