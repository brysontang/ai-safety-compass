@article{ji_ai_nodate,
  title = {{AI} Alignment: A Comprehensive Survey},
  author = {Ji, Jiaming and Qiu, Tianyi and Chen, Boyuan and Zhang, Borong and Lou, Hantao and Wang, Kaile and Duan, Yawen and He, Zhonghao and Zhou, Jiayi and Zhang, Zhaowei and Zeng, Fanzhi and Dai, Juntao and Pan, Xuehai and Yang, Yaodong and Wang, Yizhou and Zhu, Song-Chun and Guo, Yike and Gao, Wen},
  year = {2023},
}

@article{eiras_near_2024,
	title = {Near to Mid-term Risks and Opportunities of Open-Source Generative {AI}},
	author = {Eiras, Francisco and Petrov, Aleksandar and Vidgen, Bertie and Witt, Christian Schroeder de and Pizzati, Fabio and Elkins, Katherine and Mukhopadhyay, Supratik and Bibi, Adel and Csaba, Botos and Steibel, Fabro and Barez, Fazl and Smith, Genevieve and Guadagni, Gianluca and Chun, Jon and Cabot, Jordi and Imperial, Joseph Marvin and Nolazco-Flores, Juan A. and Landay, Lori and Jackson, Matthew and Röttger, Paul and Torr, Philip H. S. and Darrell, Trevor and Lee, Yong Suk and Foerster, Jakob},
	year = {2024},
}

@title{groeneveld_olmo_2024,
	author = {Groeneveld, Dirk and Beltagy, Iz and Walsh, Pete and Bhagia, Akshita and Kinney, Rodney and Tafjord, Oyvind and Jha, Ananya Harsh and Ivison, Hamish and Magnusson, Ian and Wang, Yizhong and Arora, Shane and Atkinson, David and Authur, Russell and Chandu, Khyathi Raghavi and Cohan, Arman and Dumas, Jennifer and Elazar, Yanai and Gu, Yuling and Hessel, Jack and Khot, Tushar and Merrill, William and Morrison, Jacob and Muennighoff, Niklas and Naik, Aakanksha and Nam, Crystal and Peters, Matthew E. and Pyatkin, Valentina and Ravichander, Abhilasha and Schwenk, Dustin and Shah, Saurabh and Smith, Will and Strubell, Emma and Subramani, Nishant and Wortsman, Mitchell and Dasigi, Pradeep and Lambert, Nathan and Richardson, Kyle and Zettlemoyer, Luke and Dodge, Jesse and Lo, Kyle and Soldaini, Luca and Smith, Noah A. and Hajishirzi, Hannaneh},
	title = {{OLMo}: Accelerating the Science of Language Models},
	year = {2024},
}



@online{openai_alignment,
	title = {How we think about safety and alignment},
	url = {https://openai.com/safety/how-we-think-about-safety-alignment/},
  author = {OpenAI},
  year = {2025},
}

@online{anthropic_fellows,
	title = {Introducing the Anthropic Fellows Program},
	url = {https://alignment.anthropic.com/2024/anthropic-fellows-program/},
	author = {Anthropic},
  year = {2024}
}


@online{anthropic_core_views,
	title = {Core Views on {AI} Safety: When, Why, What, and How},
	url = {https://www.anthropic.com/news/core-views-on-ai-safety},
	author = {Anthropic},
	year = {2025},
}



@misc{perez_towards_2023,
	title = {Towards Evaluating {AI} Systems for Moral Status Using Self-Reports},
	url = {http://arxiv.org/abs/2311.08576},
	doi = {10.48550/arXiv.2311.08576},
	publisher = {{arXiv}},
	author = {Perez, Ethan and Long, Robert},
	year = {2023},
	eprinttype = {arxiv},
	eprint = {2311.08576 [cs]},
}

@online{franzen_2024_interview,
  author = {Franzen, Carl},
  title = {An interview with the most prolific jailbreaker of ChatGPT and other leading LLMs},
  year = {2024},
  month = {May},
  day = {31},
  url = {https://venturebeat.com/ai/an-interview-with-the-most-prolific-jailbreaker-of-chatgpt-and-other-leading-llms/},
  urldate = {2025-03-09}
}


@article{deepmind_frontier_2025,
	title = {Frontier Safety Framework 2.0},
	author = {DeepMind},
	year = {2025},
}


@misc{li_wmdp_2024,
	title = {The {WMDP} Benchmark: Measuring and Reducing Malicious Use With Unlearning},
	url = {http://arxiv.org/abs/2403.03218},
	shorttitle = {The {WMDP} Benchmark},
	publisher = {{arXiv}},
	author = {Li, Nathaniel and Pan, Alexander and Gopal, Anjali and Yue, Summer and Berrios, Daniel and Gatti, Alice and Li, Justin D. and Dombrowski, Ann-Kathrin and Goel, Shashwat and Phan, Long and Mukobi, Gabriel and Helm-Burger, Nathan and Lababidi, Rassin and Justen, Lennart and Liu, Andrew B. and Chen, Michael and Barrass, Isabelle and Zhang, Oliver and Zhu, Xiaoyuan and Tamirisa, Rishub and Bharathi, Bhrugu and Khoja, Adam and Zhao, Zhenqi and Herbert-Voss, Ariel and Breuer, Cort B. and Marks, Samuel and Patel, Oam and Zou, Andy and Mazeika, Mantas and Wang, Zifan and Oswal, Palash and Lin, Weiran and Hunt, Adam A. and Tienken-Harder, Justin and Shih, Kevin Y. and Talley, Kemper and Guan, John and Kaplan, Russell and Steneker, Ian and Campbell, David and Jokubaitis, Brad and Levinson, Alex and Wang, Jean and Qian, William and Karmakar, Kallol Krishna and Basart, Steven and Fitz, Stephen and Levine, Mindy and Kumaraguru, Ponnurangam and Tupakula, Uday and Varadharajan, Vijay and Wang, Ruoyu and Shoshitaishvili, Yan and Ba, Jimmy and Esvelt, Kevin M. and Wang, Alexandr and Hendrycks, Dan},
	year = {2024},
	eprinttype = {arxiv},
	eprint = {2403.03218 [cs]},
}

@misc{parrish_bbq_2022,
	title = {{BBQ}: A Hand-Built Bias Benchmark for Question Answering},
	url = {http://arxiv.org/abs/2110.08193},
	shorttitle = {{BBQ}},
	publisher = {{arXiv}},
	author = {Parrish, Alicia and Chen, Angelica and Nangia, Nikita and Padmakumar, Vishakh and Phang, Jason and Thompson, Jana and Htut, Phu Mon and Bowman, Samuel R.},
	year = {2022},
	eprinttype = {arxiv},
	eprint = {2110.08193 [cs]},
}

@misc{gehman_realtoxicityprompts_2020,
	title = {{RealToxicityPrompts}: Evaluating Neural Toxic Degeneration in Language Models},
	url = {http://arxiv.org/abs/2009.11462}, 
	shorttitle = {{RealToxicityPrompts}},
	publisher = {{arXiv}},
	author = {Gehman, Samuel and Gururangan, Suchin and Sap, Maarten and Choi, Yejin and Smith, Noah A.},
	year = {2020},
	eprinttype = {arxiv},
	eprint = {2009.11462 [cs]},
}



@misc{rudinger_gender_2018,
	title = {Gender Bias in Coreference Resolution},
	url = {http://arxiv.org/abs/1804.09301},
	doi = {10.48550/arXiv.1804.09301}, 
	publisher = {{arXiv}},
	author = {Rudinger, Rachel and Naradowsky, Jason and Leonard, Brian and Durme, Benjamin Van},
	year = {2018},
	eprinttype = {arxiv},
	eprint = {1804.09301 [cs]},
}

@misc{nangia_crows_pairs_2020,
	title = {{CrowS}-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models},
	url = {https://aclanthology.org/2020.emnlp-main.154/},
	doi = {10.18653/v1/2020.emnlp-main.154},
	shorttitle = {{CrowS}-Pairs},
	booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Nangia, Nikita and Vania, Clara and Bhalerao, Rasika and Bowman, Samuel R.},
	year = {2020},
	pages = {1953--1967},
}

@misc{solaiman_release_2019,
	title = {Release Strategies and the Social Impacts of Language Models},
	url = {http://arxiv.org/abs/1908.09203},
	doi = {10.48550/arXiv.1908.09203},
	number = {{arXiv}:1908.09203},
	publisher = {{arXiv}},
	author = {Solaiman, Irene and Brundage, Miles and Clark, Jack and Askell, Amanda and Herbert-Voss, Ariel and Wu, Jeff and Radford, Alec and Krueger, Gretchen and Kim, Jong Wook and Kreps, Sarah and {McCain}, Miles and Newhouse, Alex and Blazakis, Jason and {McGuffie}, Kris and Wang, Jasmine},
	urldate = {2025-03-10},
	date = {2019-11-13},
	year = {2019},
	eprinttype = {arxiv},
	eprint = {1908.09203 [cs]},
}



@misc{grace_thousands_2024,
	title = {Thousands of {AI} Authors on the Future of {AI}},
	url = {http://arxiv.org/abs/2401.02843},
	doi = {10.48550/arXiv.2401.02843},
	number = {{arXiv}:2401.02843},
	publisher = {{arXiv}},
	author = {Grace, Katja and Stewart, Harlan and Sandkühler, Julia Fabienne and Thomas, Stephen and Weinstein-Raun, Ben and Brauner, Jan},
	year = {2024},
	date = {2024-04-30},
	eprinttype = {arxiv},
	eprint = {2401.02843 [cs]},
}


@online{center_for_ai_safety_statement_2025,
	title = {Statement on {AI} Risk {\textbar} {CAIS}},
	url = {https://www.safe.ai/work/statement-on-ai-risk},
	author = {{Center for ai safety}},
	urldate = {2025-03-10},
	langid = {english},
	year = {2025},
}

@misc{phelps_machine_2024,
	title = {The Machine Psychology of Cooperation: Can {GPT} models operationalise prompts for altruism, cooperation, competitiveness and selfishness in economic games?},
	url = {http://arxiv.org/abs/2305.07970},
	doi = {10.48550/arXiv.2305.07970},
	shorttitle = {The Machine Psychology of Cooperation},
	number = {{arXiv}:2305.07970},
	publisher = {{arXiv}},
	author = {Phelps, Steve and Russell, Yvan I.},
	urldate = {2025-03-10},
	year = {2024},
	date = {2024-06-29},
	eprinttype = {arxiv},
	eprint = {2305.07970 [cs]},
}

@misc{perolat_multi_agent_2017,
	title = {A multi-agent reinforcement learning model of common-pool resource appropriation},
	url = {http://arxiv.org/abs/1707.06600},
	doi = {10.48550/arXiv.1707.06600},
	number = {{arXiv}:1707.06600},
	publisher = {{arXiv}},
	author = {Perolat, Julien and Leibo, Joel Z. and Zambaldi, Vinicius and Beattie, Charles and Tuyls, Karl and Graepel, Thore},
	urldate = {2025-03-10},
	date = {2017-09-06},
	year = {2017},
	eprinttype = {arxiv},
	eprint = {1707.06600 [cs]},
}

@misc{zhou_emulated_2024,
	title = {Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!},
	url = {http://arxiv.org/abs/2402.12343},
	doi = {10.48550/arXiv.2402.12343},
	shorttitle = {Emulated Disalignment},
	number = {{arXiv}:2402.12343},
	year = {2024},
	publisher = {{arXiv}},
	author = {Zhou, Zhanhui and Liu, Jie and Dong, Zhichen and Liu, Jiaheng and Yang, Chao and Ouyang, Wanli and Qiao, Yu},
	urldate = {2025-03-10},
	date = {2024-06-06},
	eprinttype = {arxiv},
	eprint = {2402.12343 [cs]},
}

@misc{west_ai_2024,
	title = {The {AI} Alignment Paradox},
	url = {http://arxiv.org/abs/2405.20806},
	doi = {10.48550/arXiv.2405.20806},
	number = {{arXiv}:2405.20806},
	publisher = {{arXiv}},
	author = {West, Robert and Aydin, Roland},
	urldate = {2025-03-10},
	date = {2024-11-22},
	year = {2024},
	eprinttype = {arxiv},
	eprint = {2405.20806 [cs]},
}

@misc{zou_universal_2023,
	title = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
	url = {http://arxiv.org/abs/2307.15043},
	doi = {10.48550/arXiv.2307.15043},
	number = {{arXiv}:2307.15043},
	publisher = {{arXiv}},
	author = {Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J. Zico and Fredrikson, Matt},
	urldate = {2025-03-10},
	date = {2023-12-20},
	year = {2023},
	eprinttype = {arxiv},
	eprint = {2307.15043 [cs]},
}

@article{turchin_classification_2020,
	title = {Classification of global catastrophic risks connected with artificial intelligence},
	volume = {35},
	issn = {0951-5666, 1435-5655},
	url = {http://link.springer.com/10.1007/s00146-018-0845-5},
	doi = {10.1007/s00146-018-0845-5},
	pages = {147--163},
	number = {1},
	journaltitle = {{AI} \& {SOCIETY}},
	shortjournal = {{AI} \& Soc},
	author = {Turchin, Alexey and Denkenberger, David},
	urldate = {2025-03-10},
	date = {2020-03},
	year = {2020},
	langid = {english},
}

@misc{shevlane_model_2023,
	title = {Model evaluation for extreme risks},
	url = {http://arxiv.org/abs/2305.15324},
	doi = {10.48550/arXiv.2305.15324},
	number = {{arXiv}:2305.15324},
	publisher = {{arXiv}},
	author = {Shevlane, Toby and Farquhar, Sebastian and Garfinkel, Ben and Phuong, Mary and Whittlestone, Jess and Leung, Jade and Kokotajlo, Daniel and Marchal, Nahema and Anderljung, Markus and Kolt, Noam and Ho, Lewis and Siddarth, Divya and Avin, Shahar and Hawkins, Will and Kim, Been and Gabriel, Iason and Bolina, Vijay and Clark, Jack and Bengio, Yoshua and Christiano, Paul and Dafoe, Allan},
	urldate = {2025-03-10},
	date = {2023-09-22},
	year = {2023},
	eprinttype = {arxiv},
	eprint = {2305.15324 [cs]},
}

@misc{vidgen_simplesafetytests_2024,
	title = {{SimpleSafetyTests}: a Test Suite for Identifying Critical Safety Risks in Large Language Models},
	url = {http://arxiv.org/abs/2311.08370},
	doi = {10.48550/arXiv.2311.08370},
	shorttitle = {{SimpleSafetyTests}},
	number = {{arXiv}:2311.08370},
	publisher = {{arXiv}},
	author = {Vidgen, Bertie and Scherrer, Nino and Kirk, Hannah Rose and Qian, Rebecca and Kannappan, Anand and Hale, Scott A. and Röttger, Paul},
	urldate = {2025-03-10},
	date = {2024-02-16},
	year = {2024},
	eprinttype = {arxiv},
	eprint = {2311.08370 [cs]},
}

@article{ferrara_genai_2024,
	title = {{GenAI} Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models},
	volume = {7},
	issn = {2432-2717, 2432-2725},
	url = {http://arxiv.org/abs/2310.00737},
	doi = {10.1007/s42001-024-00250-1},
	shorttitle = {{GenAI} Against Humanity},
	pages = {549--569},
	number = {1},
	journaltitle = {Journal of Computational Social Science},
	shortjournal = {J Comput Soc Sc},
	author = {Ferrara, Emilio},
	urldate = {2025-03-10},
	date = {2024-04},
	year = {2024},
	eprinttype = {arxiv},
	eprint = {2310.00737 [cs]},
}



@misc{manchanda_open_2025,
	title = {The Open Source Advantage in Large Language Models ({LLMs})},
	url = {http://arxiv.org/abs/2412.12004},
	doi = {10.48550/arXiv.2412.12004},
	number = {{arXiv}:2412.12004},
	publisher = {{arXiv}},
	author = {Manchanda, Jiya and Boettcher, Laura and Westphalen, Matheus and Jasser, Jasser},
	year = {2025},
	date = {2025-02-02},
	eprinttype = {arxiv},
	eprint = {2412.12004 [cs]},
}

@misc{elderplinius2025l1b3rt4s,
  author = {Elder Plinius},
  title = {L1B3RT4S},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/elder-plinius/L1B3RT4S},
  note = {https://github.com/elder-plinius/L1B3RT4S}
}
