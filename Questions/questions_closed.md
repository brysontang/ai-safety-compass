[Near to Mid-term Risks and Opportunities of Open-Source Generative AI]

1. Model developers should be able to keep certain parts of how their AI systems are built hidden to protect their methods, even if it means less transparency to the public.

- Sources: (Touvron et al., 2023a), this paper
- Agree: [[Closed-source]]

2. It is important that developers retain the ability to limit or disable access to AI models if safety issues are discovered after release.

- Sources: (e.g. Solaiman 2023; Solaiman et al. 2023; Anthropic 2023)
- Agree: [[Closed-source]]

3. AI models that are freely available to everyone pose a greater risk because users can easily modify them to produce harmful or unsafe content.

- Sources: (Zou et al., 2023)
- Agree: [[Closed-source]]

[Risks and Opportunities of Open-Source Generative AI]

4. It's easier to enforce safety standards on AI models developed by large companies than on models developed and shared by the general public.

- Source: (e.g., see White House Executive Order)
- Agree: [[Closed-source]]

5. Once an AI model’s code and methods are publicly released, it becomes impossible to fully control or moderate harmful uses like scams, harassment, or disinformation at a large scale.

- Source: (Vidgen et al., 2023; Ferrara, 2024).
- Agree: [[Closed-source]]

6. Publicly sharing an AI model’s underlying code could make it harder to protect vulnerable individuals from potential misuse.

- Source: (Mei et al., 2022, 2023; Röttger et al., 2023)
- Agree: [[Closed-source]]

7. Making powerful AI models publicly available could increase the risk of catastrophic outcomes, even unintentionally.

- Sources: (Turchin and Denkenberger, 2020; Shevlane et al., 2023)
- Agree: [[Closed-source]]

[https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artificial-intelligence/]

8. Limiting public access to advanced AI models is justified if it helps a country maintain leadership in AI innovation.

- Source: (The White House, 2024)
- Agree: [[Closed-source]]

[https://www.anthropic.com/news/core-views-on-ai-safety]

9. AI developers should pace the release of advanced technologies to ensure society can adapt safely.

- Source: (Anthropic, 2023)
- Agree: [[Closed-source]]

10. Companies that invest billions in AI development deserve intellectual property protections to recoup their investments, which closed-source models provide.

- Source: I made it up
