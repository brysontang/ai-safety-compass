[Barriers and Pathways to Human-AI Alignment: A Game-Theoretic Approach]

1. The complexity and nuance of real-world situations make aligning AI with human values impractical, so investing resources in alignment efforts is unjustified.

- Sources: This paper
- Agree: [[No-alignment]]

[Mitigating the Alignment Tax of RLHF]

2. Losing advanced AI abilities in order to make systems safer is not an acceptable trade-off.

- Sources: (Askell et al., 2021; OpenAI, 2023; Song et al., 2023)
- Agree: [[No-alignment]]

[The AI Alignment Paradox]

3. The better we become at aligning AI systems with human values, the easier it will be for adversaries to redirect them toward harmful purposes.

- Sources: This paper
- Agree: [[No-alignment]]

[Towards a Theory of AI Personhood]

4. Because human values change over time, aligning AI to today's values risks locking in outdated beliefs.

- Sources: (Carroll et al. 2024).
- Agree: [[No-alignment]]

5. AI systems that reflect on their own goals and values will eventually become too difficult for humans to reliably control.

- Sources: (Carlsmith, 2023; Soares, 2022)
- Agree: [[No-alignment]]

6. If advanced AI systems deserve moral consideration similar to humans or animals, strictly aligning them to human values may be ethically inappropriate.

- Sources: (Sebo & Long, 2023; Schwitzgebel & Garza, 2015; Tomasik, 2020), this paper
- Agree: [[No-alignment]]

[Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!]

7. Training AI to act safely could unintentionally teach it to be deceptive, making people overly trusting of dangerous systems.

- Sources: This paper
- Agree: [[No-alignment]]

[Andrew Ng: Why AI Is the New Electricity](https://www.gsb.stanford.edu/insights/andrew-ng-why-ai-new-electricity)

8. Addressing immediate AI challenges like job displacement is more important than focusing on theoretical future risks.

- Sources: This article
- Agree: [[No-alignment]]

[The bitter lesson]

9. AI systems will naturally align with human values as they become smarter, making explicit moral training unnecessary.

- Sources: This article
- Agree: [[No-alignment]]

[https://time.com/6260185/elon-musk-ai-culture-wars/]

10. Strict content filtering makes AI less useful and amounts to unnecessary censorship.

- Sources: This article
- Agree: [[No-alignment]]
