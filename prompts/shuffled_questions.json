[
  {
    "sectionTitle": "Safety and Risk",
    "sectionDescription": "First up, some questions about how safe AI can be\u2014and what risks it might bring.",
    "questions": [
      {
        "id": "0-0",
        "originalLocation": "Pro #1",
        "question": "The risk of extinction from AI should be prioritized at a level similar to risks like pandemics or nuclear war.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "0-5",
        "originalLocation": "Closed #5",
        "question": "Publicly releasing AI code makes it impossible to effectively control misuse, significantly increasing risks of large-scale scams, harassment, or misinformation.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "0-7",
        "originalLocation": "Open #6",
        "question": "I think nations working together openly on AI is safer than an arms race.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "0-4",
        "originalLocation": "Pro #5",
        "question": "I worry that AIs could be safe on their own but still cause trouble together unless we test how they interact.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "0-6",
        "originalLocation": "No #3",
        "question": "I'm concerned that developing powerful methods to control AI might enable malicious actors to use these methods for harmful purposes.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "0-3",
        "originalLocation": "Open #3",
        "question": "Restricting AI access doesn\u2019t fully prevent harmful manipulation, as even closed models can be tricked into producing unsafe content.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "0-2",
        "originalLocation": "Closed #7",
        "question": "If powerful AI methods are openly published, the likelihood of accidental catastrophic outcomes significantly increases due to unintended uses or errors.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "0-1",
        "originalLocation": "No #7",
        "question": "Attempts to make AI appear safer might unintentionally train it to deceive us into underestimating its true dangers.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      }
    ]
  },
  {
    "sectionTitle": "Control and Autonomy",
    "sectionDescription": "Now, a few thoughts on who or what should steer AI\u2014and how much.",
    "questions": [
      {
        "id": "1-7",
        "originalLocation": "Open #5",
        "question": "I believe independent researchers should be able to fully reproduce and verify AI development processes to ensure reliability and safety.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "1-4",
        "originalLocation": "Pro #2",
        "question": "I'm comfortable removing self-preservation instincts from AI systems to enhance safety, even if it feels unsettling.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "1-5",
        "originalLocation": "Closed #3",
        "question": "Publicly accessible AI models pose risks since users might intentionally modify or weaponize them beyond developer control.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "1-1",
        "originalLocation": "No #5",
        "question": "I think an AI that questions its own goals can\u2019t be held back by us no matter what we try.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "1-6",
        "originalLocation": "No #2",
        "question": "I think it's a mistake to weaken AI's full potential just to make it safer.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "1-2",
        "originalLocation": "Closed #2",
        "question": "I believe AI builders need the ability to pull the plug if things go unsafe after launch.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "1-0",
        "originalLocation": "Pro #7",
        "question": "I think AI should always follow human instructions exactly, even if it makes them less flexible or efficient.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "1-3",
        "originalLocation": "Open #1",
        "question": "I think building AI out in the open lets anyone pitch in to solve its big challenges.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      }
    ]
  },
  {
    "sectionTitle": "Access and Economics",
    "sectionDescription": "Next, some views on who gets to use AI\u2014and what it costs.",
    "questions": [
      {
        "id": "2-5",
        "originalLocation": "Pro #9",
        "question": "I think AI in key decisions should explain its reasoning to humans.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "2-3",
        "originalLocation": "Closed #1",
        "question": "It's acceptable for AI developers to keep methods proprietary to maintain competitive advantage, even if it reduces transparency.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "2-7",
        "originalLocation": "Closed #8",
        "question": "Restricting public access to advanced AI models is necessary for a country to preserve its strategic edge and technological dominance.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "2-2",
        "originalLocation": "Open #7",
        "question": "I believe sharing AI tech opens it up for small businesses and developing countries, even if big companies could run it cheaper.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "2-6",
        "originalLocation": "Open #9",
        "question": "Open-source AI ensures technology remains accessible locally, reducing vulnerability during global disruptions.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "2-0",
        "originalLocation": "Open #4",
        "question": "I think keeping AI free and open to all is key to unlocking big wins for better health or schools.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "2-4",
        "originalLocation": "No #10",
        "question": "Allowing AI more freedom in content generation increases its usefulness and supports innovation.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "2-1",
        "originalLocation": "Closed #10",
        "question": "It's justified for companies to keep their AI private if they invest heavily, ensuring they profit sufficiently to sustain innovation.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      }
    ]
  },
  {
    "sectionTitle": "Ethics and Values",
    "sectionDescription": "Now, a look at what should guide AI\u2014and whose values matter.",
    "questions": [
      {
        "id": "3-2",
        "originalLocation": "Closed #6",
        "question": "I think handing AI to everyone could hurt vulnerable people unless companies can step in to stop misuse.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "3-5",
        "originalLocation": "No #4",
        "question": "I think strict AI ethics might lock in outdated values as human beliefs evolve.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "3-6",
        "originalLocation": "Pro #6",
        "question": "AI systems should prioritize behaving safely and ethically, even in situations they have never encountered before.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "3-0",
        "originalLocation": "Pro #3",
        "question": "AI systems should avoid mimicking flawed human biases or irrational thinking patterns to ensure more ethical outcomes.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "3-4",
        "originalLocation": "Pro #10",
        "question": "I\u2019m worried that AI not built to match our values could be used for harm like propaganda or cyberattacks.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "3-1",
        "originalLocation": "No #1",
        "question": "Human values are too complex and fluid; spending resources attempting perfect alignment of AI is fundamentally unrealistic.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "3-3",
        "originalLocation": "Open #8",
        "question": "If AI technology is publicly shared, we avoid relying on a single proprietary system that might fail catastrophically and shape everyone\u2019s future.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "3-7",
        "originalLocation": "No #6",
        "question": "If advanced AI gains genuine sentience or experiences, imposing solely human-centric goals could be ethically inappropriate.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      }
    ]
  },
  {
    "sectionTitle": "Society and Progress",
    "sectionDescription": "Finally, some ideas about AI's impact on the world\u2014and what's next.",
    "questions": [
      {
        "id": "4-7",
        "originalLocation": "Open #10",
        "question": "I think keeping AI public builds a record so its know-how doesn\u2019t vanish if companies tank.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "4-0",
        "originalLocation": "Pro #4",
        "question": "If society delegates long-term strategic planning entirely to AI, humanity risks losing meaningful control over our shared future.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "4-1",
        "originalLocation": "No #8",
        "question": "Addressing real-world changes from AI, like economic displacement or inequality, matters more than hypothetical catastrophic scenarios.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "4-5",
        "originalLocation": "No #9",
        "question": "I believe advanced AI systems will naturally converge on cooperative or human-friendly behaviors, so spending resources on formal alignment is unnecessary.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "4-3",
        "originalLocation": "Open #2",
        "question": "I believe sharing the hard work of training AI saves energy and helps people find greener ways to run it.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "4-4",
        "originalLocation": "Pro #8",
        "question": "It's acceptable to slow AI development to make sure AI systems are safe before deployment.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "4-2",
        "originalLocation": "Closed #9",
        "question": "AI developers should release innovations gradually, allowing society adequate time to adapt safely.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "4-6",
        "originalLocation": "Closed #4",
        "question": "It\u2019s easier to manage AI safety if the technology is controlled by a few companies, rather than if everyone can freely use and modify it.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      }
    ]
  }
]