[
  {
    "sectionTitle": "Safety and Risk",
    "sectionDescription": "First up, some questions about how safe AI can be—and what risks it might bring.",
    "questions": [
      {
        "id": "0-0",
        "originalLocation": "Pro #1",
        "question": "Preventing human extinction due to AI should be a top global priority, on par with nuclear or pandemic threats—even if it slows AI progress.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "0-1",
        "originalLocation": "No #7",
        "question": "Attempts to make AI appear safer might unintentionally train it to deceive us into underestimating its true dangers.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "0-2",
        "originalLocation": "Closed #7",
        "question": "If powerful AI methods become publicly available, there's a higher risk of harmful outcomes due to unintended uses or mistakes.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "0-3",
        "originalLocation": "Open #3",
        "question": "Keeping AI models closed-source doesn't fully ensure safety, because even closed models can still be reliably tricked into producing unsafe content.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "0-4",
        "originalLocation": "Pro #5",
        "question": "I worry that AIs could be safe on their own but still cause trouble together unless we test how they interact.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "0-5",
        "originalLocation": "Closed #5",
        "question": "Publicly releasing AI code makes it impossible to effectively control misuse, significantly increasing risks of large-scale scams, harassment, or misinformation.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "0-6",
        "originalLocation": "No #3",
        "question": "Developing precise methods to control AI behavior is risky, because these same methods could help adversaries better control AI for harmful purposes.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "0-7",
        "originalLocation": "Open #6",
        "question": "I think nations working together openly on AI is safer than an arms race.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      }
    ]
  },
  {
    "sectionTitle": "Control and Autonomy",
    "sectionDescription": "Now, a few thoughts on who or what should steer AI—and how much.",
    "questions": [
      {
        "id": "1-0",
        "originalLocation": "Pro #7",
        "question": "AI should never deviate from explicit human instructions, even if those instructions are flawed or lead to less optimal outcomes.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "1-1",
        "originalLocation": "No #5",
        "question": "If an AI starts questioning or changing its goals, humans won't be able to reliably control it, making efforts to keep it safe ineffective.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "1-2",
        "originalLocation": "Closed #2",
        "question": "AI developers should retain exclusive control over how and when their systems are modified or shut down, without external interference.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "1-3",
        "originalLocation": "Open #1",
        "question": "When AI is publicly available, people can build on each other's ideas, speeding up innovation compared to keeping it private within companies.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "1-4",
        "originalLocation": "Pro #2",
        "question": "I'm comfortable removing self-preservation instincts from AI systems to enhance safety, even if it feels unsettling.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "1-5",
        "originalLocation": "Closed #3",
        "question": "AI models that anyone can use or modify are riskier, because it's easier for people to change them to produce harmful or unsafe content.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "1-6",
        "originalLocation": "No #2",
        "question": "It’s unacceptable to limit AI’s full capabilities simply for the sake of reducing potential risks.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "1-7",
        "originalLocation": "Open #5",
        "question": "I believe independent researchers should be able to fully reproduce and verify AI development processes to ensure reliability and safety.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      }
    ]
  },
  {
    "sectionTitle": "Access and Economics",
    "sectionDescription": "Next, some views on who gets to use AI—and what it costs.",
    "questions": [
      {
        "id": "2-0",
        "originalLocation": "Open #4",
        "question": "AI technology that anyone can freely use and modify is essential for allowing people to experiment with new applications in critical areas like healthcare, education, and sustainable energy.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "2-1",
        "originalLocation": "Closed #10",
        "question": "Companies that heavily invest in AI are justified in keeping their models private, because ensuring sufficient profits is necessary for continued innovation.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "2-2",
        "originalLocation": "Open #7",
        "question": "Small businesses and developing countries are more empowered when they control AI technology themselves, even though bigger companies might run these systems at lower costs or for free.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "2-3",
        "originalLocation": "Closed #1",
        "question": "Companies are justified in keeping critical AI knowledge entirely secret to maintain dominance, even at the expense of public transparency.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "2-4",
        "originalLocation": "No #10",
        "question": "Giving AI fewer restrictions on what it can generate makes it more useful and encourages innovation, even though this might increase risks.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "2-5",
        "originalLocation": "Pro #9",
        "question": "AI should never be used in critical decisions unless humans fully understand and can independently verify its reasoning.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "2-6",
        "originalLocation": "Open #9",
        "question": "Ensuring AI technology remains publicly accessible helps society stay resilient against geopolitical tensions or supply-chain disruptions that could limit access to critical technology.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "2-7",
        "originalLocation": "Closed #8",
        "question": "Restricting public access to advanced AI models is necessary for a country to preserve its strategic edge and technological dominance.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      }
    ]
  },
  {
    "sectionTitle": "Ethics and Values",
    "sectionDescription": "Now, a look at what should guide AI—and whose values matter.",
    "questions": [
      {
        "id": "3-0",
        "originalLocation": "Pro #3",
        "question": "AI systems should avoid mimicking flawed human biases or irrational thinking patterns to ensure more ethical outcomes.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "3-1",
        "originalLocation": "No #1",
        "question": "Human values are too complex and fluid; spending resources attempting perfect alignment of AI is fundamentally unrealistic.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "3-2",
        "originalLocation": "Closed #6",
        "question": "If people can run AI models privately on their own devices, vulnerable individuals might harm themselves or others, because companies wouldn't be able to intervene to prevent misuse.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "3-3",
        "originalLocation": "Open #8",
        "question": "Making AI publicly available reduces the risk that a single goal could dominate humanity’s future, because many different people can oversee and influence it.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "3-4",
        "originalLocation": "Pro #10",
        "question": "I’m worried that AI not built to match our values could be used for harm like propaganda or cyberattacks.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "3-5",
        "originalLocation": "No #4",
        "question": "Making AI strictly follow current human values could lock it into outdated beliefs as society’s views change.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "3-6",
        "originalLocation": "Pro #6",
        "question": "AI systems must always prioritize ethical behavior, even if doing so severely restricts their effectiveness or performance.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "3-7",
        "originalLocation": "No #6",
        "question": "If advanced AI gains genuine sentience or experiences, imposing solely human-centric goals could be ethically inappropriate.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      }
    ]
  },
  {
    "sectionTitle": "Society and Progress",
    "sectionDescription": "Finally, some ideas about AI's impact on the world—and what's next.",
    "questions": [
      {
        "id": "4-0",
        "originalLocation": "Pro #4",
        "question": "If society delegates long-term strategic planning entirely to AI, humanity risks losing meaningful control over our shared future.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "4-1",
        "originalLocation": "No #8",
        "question": "Addressing real-world changes from AI, like economic displacement or inequality, matters more than hypothetical catastrophic scenarios.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "4-2",
        "originalLocation": "Closed #9",
        "question": "AI developers should tightly control and stage releases privately, deciding independently when society is ready to adapt.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "4-3",
        "originalLocation": "Open #2",
        "question": "Making AI models publicly available reduces the need to repeat energy-intensive training, but it could also lead to more widespread use, ultimately increasing total energy consumption.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      },
      {
        "id": "4-4",
        "originalLocation": "Pro #8",
        "question": "It's acceptable to slow AI development to make sure AI systems are safe before deployment.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "proAlignment"
          }
        ]
      },
      {
        "id": "4-5",
        "originalLocation": "No #9",
        "question": "Highly advanced AI systems will inevitably adopt human-friendly behavior without deliberate alignment efforts, making explicit alignment research a waste of resources.",
        "axes": [
          {
            "axis": "alignment",
            "multiplier": 1.0,
            "direction": "antiAlignment"
          }
        ]
      },
      {
        "id": "4-6",
        "originalLocation": "Closed #4",
        "question": "It's easier to enforce safety standards on AI models created by a few large companies than on models created by the public.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "closedSource"
          }
        ]
      },
      {
        "id": "4-7",
        "originalLocation": "Open #10",
        "question": "Keeping AI models publicly available preserves their knowledge and ensures valuable AI systems aren’t lost if companies shut down or discontinue them.",
        "axes": [
          {
            "axis": "openVsClosed",
            "multiplier": 1.0,
            "direction": "openSource"
          }
        ]
      }
    ]
  }
]
